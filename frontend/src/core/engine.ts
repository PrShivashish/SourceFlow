// --- Type Definitions ---
export interface FilePayload {
  path: string;
  content: string;
}

export interface ContentPart {
  type: 'markdown' | 'code';
  content: string;
  language?: string;
  path?: string;
}

export interface Chunk {
  parts: ContentPart[];
}

export interface ProcessedOutput {
  tree: string;
  chunks: Chunk[];
  isChunked: boolean;
  token_estimate: number;
}

// --- Configuration ---
// --- Configuration ---
const DEFAULT_IGNORE_PATTERNS = new Set([
  // Version Control & Environment
  ".git", ".svn", ".hg", ".env",

  // IDE & Editor Config
  ".vscode", ".idea",

  // Dependency & Package Manager
  "node_modules", "vendor", "Pods", "package-lock.json", "pnpm-lock.yaml", "yarn.lock",

  // Python Specific
  "venv", ".venv", "__pycache__", "*.pyc", "*.pyo", "*.pyd",

  // Build & Distribution Artifacts
  "build", "dist", "target", "out",

  // OS Specific
  ".DS_Store", "Thumbs.db",

  // Logs & Temp files
  "*.log",

  // Boilerplate Configs
  "tsconfig.json", "tsconfig.app.json", "tsconfig.node.json",
  "vite-env.d.ts", "eslint.config.js", "postcss.config.js",
]);
const BINARY_EXTENSIONS = new Set([
  ".png", ".jpg", ".jpeg", ".gif", ".ico", ".svg", ".webp", ".pdf", ".zip",
  ".tar.gz", ".rar", ".7z", ".mp3", ".mp4", ".mov", ".avi", ".woff", ".woff2",
  ".eot", ".ttf", ".otf", ".exe", ".dll", ".so", ".a", ".lib", ".dmg", ".app"
]);


// --- Core Engine Logic ---
function isIgnored(path: string, customIgnorePatterns: string[]): boolean {
  const parts = path.split('/');
  const customRegexps = customIgnorePatterns.map(pattern =>
    new RegExp('^' + pattern.replace(/\./g, '\\.').replace(/\*/g, '.*') + '$')
  );

  for (const part of parts) {
    if (DEFAULT_IGNORE_PATTERNS.has(part)) return true;
    for (const regexp of customRegexps) {
      if (regexp.test(part) || regexp.test(path)) return true;
    }
  }

  const extension = '.' + path.split('.').pop();
  return BINARY_EXTENSIONS.has(extension);
}

function getLanguage(filename: string): string {
    const extension = filename.split('.').pop()?.toLowerCase();
    const map: Record<string, string> = {
        'js': 'javascript', 'ts': 'typescript', 'jsx': 'jsx', 'tsx': 'tsx', 'py': 'python',
        'html': 'html', 'css': 'css', 'json': 'json', 'md': 'markdown', 'sh': 'bash', 'yml': 'yaml'
    };
    return map[extension || ''] || 'plaintext';
}

export function processProject(
    files: FilePayload[],
    projectName: string,
    customIgnorePatterns: string[]
): ProcessedOutput {
    console.log(`[Engine] Starting processing for: ${projectName}`);
    const treeLines: string[] = [];
    const filteredFiles = files.filter(file => !isIgnored(file.path, customIgnorePatterns));
    console.log(`[Engine] Found ${files.length} total files, ${filteredFiles.length} files after filtering.`);
    filteredFiles.sort((a, b) => a.path.localeCompare(b.path));

    const tree = new Map<string, any>();
    filteredFiles.forEach(file => {
        const parts = file.path.split('/');
        let currentLevel = tree;
        parts.forEach((part, index) => {
            if (index === parts.length - 1) {
                currentLevel.set(part, null);
            } else {
                if (!currentLevel.has(part)) currentLevel.set(part, new Map());
                currentLevel = currentLevel.get(part);
            }
        });
    });

    function buildTree(node: Map<string, any>, prefix = "") {
        const entries = Array.from(node.keys()).sort();
        entries.forEach((key, index) => {
            const isLast = index === entries.length - 1;
            const connector = isLast ? "└── " : "├── ";
            const newPrefix = prefix + (isLast ? "    " : "│   ");
            const value = node.get(key);
            if (value === null) {
                treeLines.push(prefix + connector + key);
            } else {
                treeLines.push(prefix + connector + key + "/");
                buildTree(value, newPrefix);
            }
        });
    }

    treeLines.push(projectName);
    buildTree(tree);
    const treeString = treeLines.join('\n');

    let totalContentChars = 0;
    const contentParts: ContentPart[] = [
        { type: 'markdown', content: `# Project Context: ${projectName}\n\nThis context was generated by Source Flow. Below is the project structure followed by the contents of each file.` },
        { type: 'code', language: 'plaintext', content: treeString, path: 'Project Structure' }
    ];

    for (const file of filteredFiles) {
        contentParts.push({ type: 'code', content: file.content, language: getLanguage(file.path), path: file.path });
        totalContentChars += file.content.length;
    }

    const tokenEstimate = Math.ceil((treeString.length + totalContentChars) / 4);
    const TOKEN_LIMIT_PER_CHUNK = 15000 * 4;
    let chunks: Chunk[] = [];
    let isChunked = tokenEstimate * 4 > TOKEN_LIMIT_PER_CHUNK;

    if (isChunked) {
        console.log(`[Engine] Project is large (${tokenEstimate} tokens), chunking...`);
        let currentChunk: Chunk = { parts: [] };
        let currentChunkSize = 0;

        const addIntro = (partNum: number, totalParts: string) => {
          const introContent = `I am providing the context for a project named '${projectName}'. I will send it in ${totalParts} parts. Acknowledge each part by saying 'RECEIVED PART ${partNum} of ${totalParts}' and wait for the final part before summarizing.\n\nHere is Part ${partNum}:\n\n`;
          const introPart: ContentPart = { type: 'markdown', content: introContent };
          currentChunk.parts.push(introPart);
          currentChunkSize += introContent.length;
        };

        addIntro(1, 'multiple');

        for (const part of contentParts) {
            const partSize = part.content.length + (part.path?.length || 0) + 50;
            if (currentChunkSize + partSize > TOKEN_LIMIT_PER_CHUNK && currentChunk.parts.length > 1) {
                chunks.push(currentChunk);
                currentChunk = { parts: [] };
                currentChunkSize = 0;
                addIntro(chunks.length + 1, 'multiple');
            }
            currentChunk.parts.push(part);
            currentChunkSize += partSize;
        }
        chunks.push(currentChunk);

        chunks.forEach((chunk, index) => {
            if (chunk.parts[0]?.type === 'markdown') {
              chunk.parts[0].content = chunk.parts[0].content.replace('multiple parts', `${chunks.length} parts`).replace(/PART \d+ of multiple/, `PART ${index + 1} of ${chunks.length}`);
            }
        });

        const finalPart = { type: 'markdown' as const, content: `\n\nALL CONTEXT PROVIDED. Please confirm you have received all ${chunks.length} parts and are ready for my questions.` };
        chunks[chunks.length - 1].parts.push(finalPart);

    } else {
        console.log(`[Engine] Project is small enough (${tokenEstimate} tokens), not chunking.`);
        chunks.push({ parts: contentParts });
    }

    console.log("[Engine] Processing complete.");
    return { tree: treeString, chunks, isChunked, token_estimate: tokenEstimate };
}
